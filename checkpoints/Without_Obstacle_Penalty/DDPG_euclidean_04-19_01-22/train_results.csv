Iteration,Reward Min,Reward Mean,Reward Max,Episode Length Mean
1.0,-43.40876975393374,-31.894554261358806,-14.96672485576454,6.875
2.0,-51.40892744376842,-28.85048237123057,-11.913931379959536,8.064516129032258
3.0,-26.56851205732825,-21.779558746293684,-12.472330301613674,11.67
4.0,-26.668917491490355,-21.700340785609118,-8.189623950676094,13.12
5.0,-26.63432842791803,-11.23512704803443,-3.6777179030183262,12.4
6.0,-21.949130514738037,-4.85628838863226,-1.7735199119117908,11.84
7.0,-12.13865643128264,-4.027681115712479,-1.7735199119117908,11.96
8.0,-13.517552514612106,-2.7376042042933504,6.685453884450382,11.95
9.0,-4.045243720795703,-1.017813020661296,6.662963549920768,11.96
10.0,-4.169057332562652,-2.8596314279173694,6.529035040766956,11.99
11.0,-4.414096892150788,-4.0626153143365284,-3.630365944194331,12.0
12.0,-4.424503567500814,-4.095405183209825,-3.9191537148647484,12.0
13.0,-4.575882778760864,-2.7474655954883733,4.194351890327994,12.18
14.0,-4.588287802895017,-1.0843228347560283,4.234926119406339,12.39
15.0,-4.513594119599851,-0.595297170827014,6.590461953420693,11.92
